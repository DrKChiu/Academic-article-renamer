{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-intro",
   "metadata": {},
   "source": [
    "# EMA Worry Analysis with medGemma\n",
    "\n",
    "This notebook analyzes Ecological Momentary Assessment (EMA) text data to detect worry patterns using medGemma.\n",
    "The data is expected to be exported from m-path software in CSV format.\n",
    "\n",
    "## Features:\n",
    "- Load and process m-path EMA data\n",
    "- Use medGemma to classify worry presence (1) or absence (0)\n",
    "- Generate analysis reports and visualizations\n",
    "- Export results for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "config-section",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Update these settings according to your setup:"
   ]
  },
  {
   "cell_type": "code",
   "id": "configuration",
   "metadata": {},
   "source": "# File paths\nDATA_FILE_PATH = 'sample_mpath_ema_data.csv'  # Update with your m-path export file\nOUTPUT_FILE_PATH = 'ema_worry_analysis_results.csv'\n\n# Column names (adjust based on your m-path export format)\nTEXT_COLUMN = 'response_text'\nPARTICIPANT_COLUMN = 'participant_id'\nTIMESTAMP_COLUMN = 'timestamp'\n\n# LM Studio API configuration\nLM_STUDIO_API_URL = 'http://localhost:1234/v1/chat/completions'  # LM Studio local endpoint\nLM_STUDIO_MODEL = 'medgemma-27b-text-it-mlx'  # Model name in LM Studio\n\n# Analysis parameters\nBATCH_SIZE = 10  # Process texts in batches\nDELAY_BETWEEN_REQUESTS = 2  # Seconds between API calls (LM Studio might need more time)",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "source": [
    "# Load the EMA data\n",
    "try:\n",
    "    df = pd.read_csv(DATA_FILE_PATH)\n",
    "    print(f\"Successfully loaded data from {DATA_FILE_PATH}\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    required_columns = [TEXT_COLUMN, PARTICIPANT_COLUMN, TIMESTAMP_COLUMN]\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"\\nWarning: Missing required columns: {missing_columns}\")\n",
    "        print(\"Please update the column names in the configuration section.\")\n",
    "    else:\n",
    "        print(\"\\nAll required columns found!\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {DATA_FILE_PATH}\")\n",
    "    print(\"Please update DATA_FILE_PATH or ensure the file exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-exploration",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "if 'df' in locals():\n",
    "    print(\"=== Dataset Overview ===\")\n",
    "    print(f\"Total responses: {len(df)}\")\n",
    "    print(f\"Unique participants: {df[PARTICIPANT_COLUMN].nunique()}\")\n",
    "    print(f\"Date range: {df[TIMESTAMP_COLUMN].min()} to {df[TIMESTAMP_COLUMN].max()}\")\n",
    "    \n",
    "    print(\"\\n=== Sample responses ===\")\n",
    "    for i, row in df.head(3).iterrows():\n",
    "        print(f\"Participant {row[PARTICIPANT_COLUMN]}: {row[TEXT_COLUMN][:100]}...\")\n",
    "    \n",
    "    print(\"\\n=== Text length statistics ===\")\n",
    "    df['text_length'] = df[TEXT_COLUMN].str.len()\n",
    "    print(df['text_length'].describe())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "medgemma-setup",
   "metadata": {},
   "source": [
    "## medGemma Integration\n",
    "\n",
    "This section sets up the connection to medGemma for worry classification."
   ]
  },
  {
   "cell_type": "code",
   "id": "medgemma-functions",
   "metadata": {},
   "source": "def classify_worry_with_medgemma(text):\n    \"\"\"\n    Classify worry presence in text using medGemma via LM Studio.\n    Returns 1 for worry present, 0 for worry absent.\n    \"\"\"\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a medical AI assistant specialized in mental health assessment. Your task is to analyze text and determine if it contains expressions of worry, anxiety, or concern. Respond with only '1' if worry/anxiety/concern is present, or '0' if absent.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"Analyze the following text and determine if it contains expressions of worry, anxiety, or concern.\n\nText: \"{text}\"\n\nInstructions:\n- Respond with only \"1\" if worry/anxiety/concern is present\n- Respond with only \"0\" if no worry/anxiety/concern is detected\n- Look for keywords like: worried, anxious, concerned, stressed, nervous, afraid, fear, overthinking\n- Consider implicit expressions of worry (e.g., \"what if\", \"I can't stop thinking about\")\n\nResponse (1 or 0 only):\"\"\"\n        }\n    ]\n    \n    try:\n        payload = {\n            \"model\": LM_STUDIO_MODEL,\n            \"messages\": messages,\n            \"temperature\": 0.1,\n            \"max_tokens\": 10,\n            \"stream\": False\n        }\n        \n        response = requests.post(LM_STUDIO_API_URL, json=payload, timeout=30)\n        response.raise_for_status()\n        \n        result = response.json()\n        prediction = result['choices'][0]['message']['content'].strip()\n        \n        # Parse the response\n        if prediction in ['1', '1.0', 'YES', 'yes', 'Yes']:\n            return 1\n        elif prediction in ['0', '0.0', 'NO', 'no', 'No']:\n            return 0\n        else:\n            # If response is unclear, try to extract number\n            if '1' in prediction:\n                return 1\n            elif '0' in prediction:\n                return 0\n            else:\n                print(f\"Warning: Unclear response '{prediction}' for text: {text[:50]}... Defaulting to 0.\")\n                return 0\n                \n    except requests.exceptions.RequestException as e:\n        print(f\"API request failed for text '{text[:50]}...': {e}\")\n        return 0\n    except Exception as e:\n        print(f\"Error processing text '{text[:50]}...': {e}\")\n        return 0\n\ndef test_lmstudio_connection():\n    \"\"\"\n    Test the connection to LM Studio API.\n    \"\"\"\n    test_text = \"I'm really worried about my exam tomorrow. I can't stop thinking about failing.\"\n    \n    print(f\"Testing LM Studio connection with: '{test_text}'\")\n    \n    try:\n        result = classify_worry_with_medgemma(test_text)\n        print(f\"Test successful! Worry classification: {result}\")\n        return True\n    except Exception as e:\n        print(f\"Connection test failed: {e}\")\n        print(\"\\\\nTroubleshooting:\")\n        print(\"1. Ensure LM Studio is running with a model loaded\")\n        print(\"2. Check that the Local Server is started in LM Studio\")\n        print(\"3. Verify the API URL (default: http://localhost:1234/v1/chat/completions)\")\n        print(\"4. Make sure medgemma-27b-text-it-mlx is loaded in LM Studio\")\n        return False",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "test-connection",
   "metadata": {},
   "source": "# Test LM Studio connection\nconnection_success = test_lmstudio_connection()",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "worry-analysis",
   "metadata": {},
   "source": [
    "## Worry Analysis\n",
    "\n",
    "Process all text responses through medGemma for worry classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-worry",
   "metadata": {},
   "source": [
    "if 'df' in locals() and connection_success:\n",
    "    print(f\"Starting worry analysis on {len(df)} text responses...\")\n",
    "    print(f\"Processing in batches of {BATCH_SIZE} with {DELAY_BETWEEN_REQUESTS}s delay\")\n",
    "    \n",
    "    # Initialize results\n",
    "    worry_scores = []\n",
    "    processed_count = 0\n",
    "    \n",
    "    # Process texts in batches\n",
    "    for i, text in enumerate(df[TEXT_COLUMN]):\n",
    "        if pd.isna(text) or text.strip() == '':\n",
    "            worry_scores.append(0)\n",
    "        else:\n",
    "            score = classify_worry_with_medgemma(str(text))\n",
    "            worry_scores.append(score)\n",
    "        \n",
    "        processed_count += 1\n",
    "        \n",
    "        # Progress update\n",
    "        if processed_count % BATCH_SIZE == 0:\n",
    "            progress = (processed_count / len(df)) * 100\n",
    "            print(f\"Progress: {processed_count}/{len(df)} ({progress:.1f}%)\")\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "    \n",
    "    # Add results to dataframe\n",
    "    df['worry_score'] = worry_scores\n",
    "    \n",
    "    print(f\"\\nAnalysis complete! Processed {processed_count} responses.\")\n",
    "    print(f\"Worry detected in {sum(worry_scores)} responses ({(sum(worry_scores)/len(worry_scores)*100):.1f}%)\")\n",
    "\n",
    "elif 'df' not in locals():\n",
    "    print(\"Please load data first by running the data loading cell.\")\n",
    "elif not connection_success:\n",
    "    print(\"Please fix the medGemma connection before proceeding with analysis.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "results-analysis",
   "metadata": {},
   "source": [
    "## Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "source": [
    "if 'worry_score' in df.columns:\n",
    "    print(\"=== WORRY ANALYSIS SUMMARY ===\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_responses = len(df)\n",
    "    worry_responses = df['worry_score'].sum()\n",
    "    worry_percentage = (worry_responses / total_responses) * 100\n",
    "    \n",
    "    print(f\"Total responses analyzed: {total_responses}\")\n",
    "    print(f\"Responses with worry detected: {worry_responses}\")\n",
    "    print(f\"Percentage with worry: {worry_percentage:.1f}%\")\n",
    "    \n",
    "    # Per-participant analysis\n",
    "    participant_stats = df.groupby(PARTICIPANT_COLUMN).agg({\n",
    "        'worry_score': ['count', 'sum', 'mean']\n",
    "    }).round(2)\n",
    "    participant_stats.columns = ['Total_Responses', 'Worry_Count', 'Worry_Rate']\n",
    "    \n",
    "    print(\"\\n=== PER-PARTICIPANT WORRY RATES ===\")\n",
    "    print(participant_stats)\n",
    "    \n",
    "    # Show examples of worry vs non-worry responses\n",
    "    print(\"\\n=== EXAMPLES OF CLASSIFIED RESPONSES ===\")\n",
    "    \n",
    "    worry_examples = df[df['worry_score'] == 1][TEXT_COLUMN].head(3)\n",
    "    no_worry_examples = df[df['worry_score'] == 0][TEXT_COLUMN].head(3)\n",
    "    \n",
    "    print(\"\\nWorry detected (score = 1):\")\n",
    "    for i, text in enumerate(worry_examples, 1):\n",
    "        print(f\"{i}. {text}\")\n",
    "    \n",
    "    print(\"\\nNo worry detected (score = 0):\")\n",
    "    for i, text in enumerate(no_worry_examples, 1):\n",
    "        print(f\"{i}. {text}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualizations",
   "metadata": {},
   "source": [
    "if 'worry_score' in df.columns:\n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Overall worry distribution\n",
    "    worry_counts = df['worry_score'].value_counts().sort_index()\n",
    "    axes[0, 0].bar(['No Worry (0)', 'Worry (1)'], worry_counts.values, \n",
    "                   color=['lightblue', 'salmon'])\n",
    "    axes[0, 0].set_title('Overall Worry Distribution')\n",
    "    axes[0, 0].set_ylabel('Number of Responses')\n",
    "    \n",
    "    # Add percentages on bars\n",
    "    for i, v in enumerate(worry_counts.values):\n",
    "        pct = (v / total_responses) * 100\n",
    "        axes[0, 0].text(i, v + 0.5, f'{v}\\n({pct:.1f}%)', \n",
    "                       ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Worry rates by participant\n",
    "    participant_worry_rates = participant_stats['Worry_Rate'].sort_values(ascending=True)\n",
    "    axes[0, 1].barh(range(len(participant_worry_rates)), participant_worry_rates.values)\n",
    "    axes[0, 1].set_yticks(range(len(participant_worry_rates)))\n",
    "    axes[0, 1].set_yticklabels(participant_worry_rates.index)\n",
    "    axes[0, 1].set_title('Worry Rate by Participant')\n",
    "    axes[0, 1].set_xlabel('Worry Rate (0-1)')\n",
    "    \n",
    "    # 3. Text length vs worry\n",
    "    worry_texts = df[df['worry_score'] == 1]['text_length']\n",
    "    no_worry_texts = df[df['worry_score'] == 0]['text_length']\n",
    "    \n",
    "    axes[1, 0].boxplot([no_worry_texts, worry_texts], \n",
    "                       labels=['No Worry', 'Worry'])\n",
    "    axes[1, 0].set_title('Text Length Distribution by Worry Score')\n",
    "    axes[1, 0].set_ylabel('Text Length (characters)')\n",
    "    \n",
    "    # 4. Timeline analysis (if timestamp is available)\n",
    "    try:\n",
    "        df['timestamp_parsed'] = pd.to_datetime(df[TIMESTAMP_COLUMN])\n",
    "        df['date'] = df['timestamp_parsed'].dt.date\n",
    "        \n",
    "        daily_worry = df.groupby('date')['worry_score'].mean()\n",
    "        axes[1, 1].plot(daily_worry.index, daily_worry.values, marker='o')\n",
    "        axes[1, 1].set_title('Daily Worry Rate Over Time')\n",
    "        axes[1, 1].set_ylabel('Average Worry Score')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "    except Exception as e:\n",
    "        axes[1, 1].text(0.5, 0.5, f'Timeline analysis unavailable\\n{str(e)}', \n",
    "                        ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        axes[1, 1].set_title('Timeline Analysis')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig('ema_worry_analysis_plots.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nVisualization saved as 'ema_worry_analysis_plots.png'\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "export-results",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-data",
   "metadata": {},
   "source": [
    "if 'worry_score' in df.columns:\n",
    "    # Prepare export dataframe\n",
    "    export_df = df[[PARTICIPANT_COLUMN, TIMESTAMP_COLUMN, TEXT_COLUMN, 'worry_score', 'text_length']].copy()\n",
    "    export_df.columns = ['participant_id', 'timestamp', 'text_response', 'worry_score', 'text_length']\n",
    "    \n",
    "    # Add analysis metadata\n",
    "    export_df['analysis_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    export_df['model_used'] = MEDGEMMA_MODEL\n",
    "    \n",
    "    # Save to CSV\n",
    "    export_df.to_csv(OUTPUT_FILE_PATH, index=False)\n",
    "    print(f\"Results exported to: {OUTPUT_FILE_PATH}\")\n",
    "    \n",
    "    # Create summary report\n",
    "    summary_report = f\"\"\"EMA WORRY ANALYSIS REPORT\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Model: {MEDGEMMA_MODEL}\n",
    "\n",
    "DATASET SUMMARY:\n",
    "- Total responses: {total_responses}\n",
    "- Unique participants: {df[PARTICIPANT_COLUMN].nunique()}\n",
    "- Responses with worry: {worry_responses} ({worry_percentage:.1f}%)\n",
    "- Average text length: {df['text_length'].mean():.1f} characters\n",
    "\n",
    "PER-PARTICIPANT STATISTICS:\n",
    "{participant_stats.to_string()}\n",
    "\n",
    "FILES GENERATED:\n",
    "- Detailed results: {OUTPUT_FILE_PATH}\n",
    "- Visualizations: ema_worry_analysis_plots.png\n",
    "- Summary report: ema_worry_analysis_report.txt\n",
    "\"\"\"\n",
    "    \n",
    "    with open('ema_worry_analysis_report.txt', 'w') as f:\n",
    "        f.write(summary_report)\n",
    "    \n",
    "    print(\"Summary report saved as: ema_worry_analysis_report.txt\")\n",
    "    print(\"\\n=== ANALYSIS COMPLETE ===\")\n",
    "    print(f\"Check the following files for results:\")\n",
    "    print(f\"- {OUTPUT_FILE_PATH} (detailed data)\")\n",
    "    print(f\"- ema_worry_analysis_plots.png (visualizations)\")\n",
    "    print(f\"- ema_worry_analysis_report.txt (summary report)\")\n",
    "\n",
    "else:\n",
    "    print(\"No analysis results to export. Please run the worry analysis first.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "troubleshooting",
   "metadata": {},
   "source": [
    "## Troubleshooting & Notes\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "1. **medGemma Connection Failed**\n",
    "   - Ensure Ollama is running: `ollama serve`\n",
    "   - Install medGemma: `ollama pull medgemma`\n",
    "   - Check API URL in configuration\n",
    "\n",
    "2. **Data Loading Issues**\n",
    "   - Verify file path is correct\n",
    "   - Check column names match your m-path export\n",
    "   - Ensure CSV file is properly formatted\n",
    "\n",
    "3. **Analysis Performance**\n",
    "   - Adjust BATCH_SIZE and DELAY_BETWEEN_REQUESTS\n",
    "   - For large datasets, consider processing in chunks\n",
    "\n",
    "### Data Format Notes:\n",
    "- This notebook expects CSV format from m-path export\n",
    "- Required columns: participant_id, timestamp, response_text\n",
    "- Text responses should contain the participant's written responses\n",
    "\n",
    "### Model Performance:\n",
    "- medGemma is optimized for medical/mental health text analysis\n",
    "- Results are binary: 1 (worry present) or 0 (worry absent)\n",
    "- Consider manual validation of a sample for quality assurance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}